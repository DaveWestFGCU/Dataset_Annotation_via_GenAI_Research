{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Config",
   "id": "5334d626f21bc063"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:08:44.838416Z",
     "start_time": "2025-02-05T19:08:44.835669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import_location = 'datasets/goemotions/ekman_6_single_label/poc_subset/goemotions_6_single_poc.csv'\n",
    "export_location = 'datasets/goemotions/ekman_6_single_label/poc_subset/ai_labeled/goemotions_6_single_poc_ai_labeled.csv'\n",
    "overwrite_previous_labels = True\n",
    "\n",
    "datasets = ['GoEmotions POC']\n",
    "ai_models = ['Llama3.1 8B instruct-q8', 'DeepSeek-R1 14B'] # 'Llama3.1 8B instruct-q8', 'DeepSeek-R1 14B', 'GPT 4o-mini', 'o3-mini'\n",
    "\n",
    "remove_others = True\n",
    "\n",
    "sample_size = 50\n",
    "random_seed = 418   #   I'm a teacup\n",
    "\n",
    "from config_files.dataset_config import dataset as dataset_config\n",
    "from config_files import gen_ai_config"
   ],
   "id": "842329c4fabe53f8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:08:44.858901Z",
     "start_time": "2025-02-05T19:08:44.856105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ollama\n",
    "from ollama import ResponseError\n",
    "from openai import OpenAI"
   ],
   "id": "63ea6ed41efba937",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Label Generation Functions",
   "id": "dc624534e3d9c55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build Label Prompt",
   "id": "4f7044a9ef6573fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:08:44.873808Z",
     "start_time": "2025-02-05T19:08:44.870493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_label_prompt(dataset_id, text, event = None):\n",
    "    from config_files import prompts\n",
    "\n",
    "    prompt = prompts.prompt[dataset_id]['labels'].replace('<text>', text)\n",
    "\n",
    "    if event:\n",
    "        prompt = prompts.prompt[dataset_id]['labels w/ context'].replace('<context>', prompts.prompt[dataset_id]['context'][event])\n",
    "\n",
    "\n",
    "    return prompt"
   ],
   "id": "ade2bbebc254656e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate AI Label",
   "id": "c0ae1e6e7652a163"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:08:44.884918Z",
     "start_time": "2025-02-05T19:08:44.880984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_synthetic_label(dataset_details, genAI_details, label_prompt):\n",
    "    if genAI_details[\"platform\"] == \"Ollama\":\n",
    "        response = ollama.chat(\n",
    "            model=genAI_details[\"id\"],\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": label_prompt\n",
    "            }]\n",
    "        )\n",
    "\n",
    "        return response[\"message\"][\"content\"]\n",
    "\n",
    "    elif genAI_details[\"platform\"] == \"OpenAI\":\n",
    "        client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=genAI_details[\"id\"],\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": label_prompt,\n",
    "            }],\n",
    "            n=dataset_details[\"num_labelers\"]\n",
    "        )\n",
    "\n",
    "        response_text = []\n",
    "        for choice in response.choices:\n",
    "            response_text.append(choice.message.content)\n",
    "\n",
    "        return response_text"
   ],
   "id": "feeb3f067846de42",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Parse Label Response",
   "id": "55fb63cf08472153"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:08:44.913498Z",
     "start_time": "2025-02-05T19:08:44.909755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_label_response(response, dataset_details, cot_terminator = None):\n",
    "    if cot_terminator:      #   Remove the reasoning layer text for Chain-of-Thought models\n",
    "        response.find(cot_terminator)\n",
    "        response = response[response.find(cot_terminator):]\n",
    "\n",
    "    for label in dataset_details[\"label_list\"]:\n",
    "        if label.lower() in response.lower():\n",
    "            return label\n",
    "\n",
    "    # Label name not found, look for ID number\n",
    "    for i in range(1, len(dataset_details[\"label_list\"]) + 1):\n",
    "        if str(i) in response:\n",
    "            return dataset_details[\"label_list\"][i-1]\n",
    "\n",
    "    # Label not found\n",
    "    CRED = '\\33[91m'\n",
    "    CEND = '\\33[0m'\n",
    "    print(f\"{CRED}NO LABEL FOUND:{CEND} {response}\")\n",
    "    return None"
   ],
   "id": "cdc5b43bc5c93439",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Label Record",
   "id": "65c3cbaba806cd7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:08:44.922842Z",
     "start_time": "2025-02-05T19:08:44.918011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_label(dataset_details, gen_ai_details, text, event=None):\n",
    "    label_prompt = build_label_prompt(dataset_details['id'], text, event)\n",
    "\n",
    "    labels = []\n",
    "    responses = []\n",
    "    print(\"Labels: \", end=\"\")\n",
    "    if gen_ai_details['platform'] == \"Ollama\":\n",
    "\n",
    "        for i in range(dataset_details['num_labelers']):\n",
    "            label_response = generate_synthetic_label(dataset_details, gen_ai_details, label_prompt)\n",
    "            responses.insert(len(responses), label_response)\n",
    "            labels.append(parse_label_response(label_response, dataset_details, gen_ai_details['terminator']))\n",
    "\n",
    "            if i > 0:\n",
    "                print(\", \", end=\"\")\n",
    "            print(f\"{labels[i]}\", end=\"\")\n",
    "\n",
    "    elif gen_ai_details['platform'] == \"OpenAI\":\n",
    "        responses = generate_synthetic_label(dataset_details, gen_ai_details, label_prompt)\n",
    "        for i, response in enumerate(responses):\n",
    "            labels.append(parse_label_response(response, dataset_details))\n",
    "\n",
    "            if i > 0:\n",
    "                print(\", \", end=\"\")\n",
    "            print(f\"{labels[i]}\", end=\"\")\n",
    "\n",
    "    consensus_label = None\n",
    "\n",
    "    if dataset_details[\"label_format\"] == \"single\":\n",
    "        # Single label dataset\n",
    "        for potential_label in dataset_details[\"label_list\"]:\n",
    "            if labels.count(potential_label) >= dataset_details[\"num_consensus\"]:\n",
    "                consensus_label = potential_label\n",
    "                print(f\"\\n\\tConsensus: {consensus_label}\")\n",
    "\n",
    "    elif dataset_details[\"label_format\"] == \"multi\":\n",
    "        # To be implemented if used with any multilabel datasets\n",
    "        pass\n",
    "\n",
    "    return consensus_label, labels, responses"
   ],
   "id": "54d1f1aa83a4a12e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Main Loop",
   "id": "c43ee0f393f16bed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:09:09.668127Z",
     "start_time": "2025-02-05T19:08:44.931605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset in datasets:\n",
    "    dataset_details = dataset_config[dataset]               #   Get dataset info\n",
    "    df_dataset = pd.read_csv(import_location)    #  Load dataset\n",
    "\n",
    "    for ai_model in ai_models:\n",
    "        ai_details = gen_ai_config.model[ai_model]                          #   Get model info\n",
    "\n",
    "        if overwrite_previous_labels is False and ai_details['id'] in df_dataset.columns:\n",
    "            continue\n",
    "\n",
    "        df_dataset.insert(len(df_dataset.columns), ai_details['id'], '')    #   Create a new column or clear old data for the AI generated labels\n",
    "\n",
    "        os.makedirs(f'datasets/goemotions/ekman_6_single_label/poc_subset/ai_labeled/ai_responses/{ai_model}/', exist_ok=True)\n",
    "\n",
    "        for index, row in df_dataset.iterrows():\n",
    "            successful = False\n",
    "            with open(f'datasets/goemotions/ekman_6_single_label/poc_subset/ai_labeled/ai_responses/{ai_model}/{dataset_details['id']}_{index}.txt', 'w', encoding=\"utf-8\") as file:\n",
    "                while not successful:\n",
    "                    try:\n",
    "                        if 'context' in df_dataset.columns:\n",
    "                            label, labels, responses = get_label(dataset_details, ai_details, row.text, row.event)\n",
    "                        else:\n",
    "                            label, labels, responses = get_label(dataset_details, ai_details, row.text)\n",
    "\n",
    "                    except ResponseError:  #   Recover from a CUDA illegal memory access error\n",
    "                        from time import sleep\n",
    "                        sleep(5)\n",
    "\n",
    "                    else:\n",
    "                        df_dataset.at[index, ai_details['id']] = label\n",
    "                        for line in responses:\n",
    "                            file.write(f\"{line}\\n\")\n",
    "                        successful = True\n",
    "\n",
    "        display(df_dataset)\n"
   ],
   "id": "6ec01de51bd1673e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: joy, joy, joy\n",
      "\tConsensus: joy\n",
      "Labels: \u001B[91mNO LABEL FOUND:\u001B[0m Based on the provided text and emotion definitions, I would identify the emotion expressed by the writer as:\n",
      "\n",
      "**Gratitude**\n",
      "\n",
      "The writer expresses appreciation and thankfulness towards the person who provided the information (i.e., \"Thanks for that\"). This indicates a positive emotional tone, which aligns with the definition of gratitude.\n",
      "None, joy\u001B[91mNO LABEL FOUND:\u001B[0m The emotion most expressed by the writer of this text is gratitude.\n",
      "\n",
      "Specifically, the writer is expressing approval and appreciation (gratitude) towards the original poster's response, using phrases such as \"I'm gonna save your answer\" and \"Thanks for that\". This suggests a positive emotional tone, indicating that the writer values the information provided and is thankful for it.\n",
      ", NoneLabels: anger, anger, anger\n",
      "\tConsensus: anger\n",
      "Labels: joy, joy, anger\n",
      "\tConsensus: joy\n",
      "Labels: \u001B[91mNO LABEL FOUND:\u001B[0m Based on the provided definition and examples of emotions, I would identify the emotion most expressed by the writer as amusement.\n",
      "\n",
      "The phrase \"hilarious responses\" suggests that the writer is entertained or finds something funny about the situation. This matches with the definition of amusement: \"Finding something funny or being entertained.\"\n",
      "None, joy\u001B[91mNO LABEL FOUND:\u001B[0m Based on the given text and emotion definitions, I would identify the emotion expressed by the writer as amusement.\n",
      "\n",
      "The phrase \"hilarious responses\" suggests that the writer found something amusing or entertaining. The context of the comment implies that someone's reactions to a high price were unexpected and comical, which triggered amusement in the writer.\n",
      ", NoneLabels: anger"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 23\u001B[0m\n\u001B[0;32m     21\u001B[0m         label, labels, responses \u001B[38;5;241m=\u001B[39m get_label(dataset_details, ai_details, row\u001B[38;5;241m.\u001B[39mtext, row\u001B[38;5;241m.\u001B[39mevent)\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 23\u001B[0m         label, labels, responses \u001B[38;5;241m=\u001B[39m \u001B[43mget_label\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_details\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mai_details\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ResponseError:  \u001B[38;5;66;03m#   Recover from a CUDA illegal memory access error\u001B[39;00m\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtime\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m sleep\n",
      "Cell \u001B[1;32mIn[18], line 10\u001B[0m, in \u001B[0;36mget_label\u001B[1;34m(dataset_details, gen_ai_details, text, event)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gen_ai_details[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplatform\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOllama\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(dataset_details[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_labelers\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m---> 10\u001B[0m         label_response \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_synthetic_label\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_details\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgen_ai_details\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_prompt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m         responses\u001B[38;5;241m.\u001B[39minsert(\u001B[38;5;28mlen\u001B[39m(responses), label_response)\n\u001B[0;32m     12\u001B[0m         labels\u001B[38;5;241m.\u001B[39mappend(parse_label_response(label_response, dataset_details, gen_ai_details[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mterminator\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "Cell \u001B[1;32mIn[16], line 3\u001B[0m, in \u001B[0;36mgenerate_synthetic_label\u001B[1;34m(dataset_details, genAI_details, label_prompt)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_synthetic_label\u001B[39m(dataset_details, genAI_details, label_prompt):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m genAI_details[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplatform\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOllama\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m----> 3\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[43mollama\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenAI_details\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_prompt\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m genAI_details[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplatform\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOpenAI\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\ollama\\_client.py:333\u001B[0m, in \u001B[0;36mClient.chat\u001B[1;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001B[0m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mchat\u001B[39m(\n\u001B[0;32m    290\u001B[0m   \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    291\u001B[0m   model: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    298\u001B[0m   keep_alive: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    299\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001B[0;32m    300\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;124;03m  Create a chat response using the requested model.\u001B[39;00m\n\u001B[0;32m    302\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    331\u001B[0m \u001B[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001B[39;00m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 333\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43mChatResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mPOST\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/api/chat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatRequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    338\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_copy_messages\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    340\u001B[0m \u001B[43m      \u001B[49m\u001B[43mtools\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtool\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtool\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_copy_tools\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtools\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    343\u001B[0m \u001B[43m      \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[43m      \u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_alive\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_dump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexclude_none\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    347\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\ollama\\_client.py:178\u001B[0m, in \u001B[0;36mClient._request\u001B[1;34m(self, cls, stream, *args, **kwargs)\u001B[0m\n\u001B[0;32m    174\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpart)\n\u001B[0;32m    176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m inner()\n\u001B[1;32m--> 178\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mjson())\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\ollama\\_client.py:118\u001B[0m, in \u001B[0;36mClient._request_raw\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_request_raw\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    117\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 118\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m     r\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpx\\_client.py:825\u001B[0m, in \u001B[0;36mClient.request\u001B[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001B[0m\n\u001B[0;32m    810\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    812\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_request(\n\u001B[0;32m    813\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[0;32m    814\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    823\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mextensions,\n\u001B[0;32m    824\u001B[0m )\n\u001B[1;32m--> 825\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpx\\_client.py:914\u001B[0m, in \u001B[0;36mClient.send\u001B[1;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[0;32m    910\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_timeout(request)\n\u001B[0;32m    912\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[1;32m--> 914\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    916\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    921\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpx\\_client.py:942\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[1;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[0;32m    939\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[0;32m    941\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 942\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    948\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpx\\_client.py:979\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[1;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[0;32m    976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    977\u001B[0m     hook(request)\n\u001B[1;32m--> 979\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    981\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpx\\_client.py:1014\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m   1009\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1010\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1011\u001B[0m     )\n\u001B[0;32m   1013\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[1;32m-> 1014\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[0;32m   1018\u001B[0m response\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m request\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    237\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[0;32m    238\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    239\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    247\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    248\u001B[0m )\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[1;32m--> 250\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[0;32m    255\u001B[0m     status_code\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mstatus,\n\u001B[0;32m    256\u001B[0m     headers\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m    257\u001B[0m     stream\u001B[38;5;241m=\u001B[39mResponseStream(resp\u001B[38;5;241m.\u001B[39mstream),\n\u001B[0;32m    258\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    259\u001B[0m )\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    253\u001B[0m         closing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_requests_to_connections()\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_connections(closing)\n\u001B[1;32m--> 256\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    232\u001B[0m connection \u001B[38;5;241m=\u001B[39m pool_request\u001B[38;5;241m.\u001B[39mwait_for_connection(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    234\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[1;32m--> 236\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[0;32m    244\u001B[0m     pool_request\u001B[38;5;241m.\u001B[39mclear_connection()\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_closed\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[0;32m    135\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_closed()\n\u001B[1;32m--> 136\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs\n\u001B[0;32m     99\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[0;32m    100\u001B[0m     (\n\u001B[0;32m    101\u001B[0m         http_version,\n\u001B[0;32m    102\u001B[0m         status,\n\u001B[0;32m    103\u001B[0m         reason_phrase,\n\u001B[0;32m    104\u001B[0m         headers,\n\u001B[0;32m    105\u001B[0m         trailing_data,\n\u001B[1;32m--> 106\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    107\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    108\u001B[0m         http_version,\n\u001B[0;32m    109\u001B[0m         status,\n\u001B[0;32m    110\u001B[0m         reason_phrase,\n\u001B[0;32m    111\u001B[0m         headers,\n\u001B[0;32m    112\u001B[0m     )\n\u001B[0;32m    114\u001B[0m network_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_stream\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_response_headers\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    174\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeouts\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 177\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    178\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mResponse):\n\u001B[0;32m    179\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_event\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    214\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[1;32m--> 217\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_network_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    219\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[0;32m    222\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    223\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    227\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mtheir_state \u001B[38;5;241m==\u001B[39m h11\u001B[38;5;241m.\u001B[39mSEND_RESPONSE:\n",
      "File \u001B[1;32mE:\\Projects\\PythonProject\\Dataset_Labeling_via_GenAI\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001B[0m, in \u001B[0;36mSyncStream.read\u001B[1;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[0;32m    127\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n\u001B[1;32m--> 128\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "f8d347ec37718c0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for dataset in datasets:\n",
    "    dataset_details = dataset_config[dataset]               #   Get dataset info\n",
    "    df_dataset = pd.read_csv(dataset_details['relpath'])    #  Load dataset\n",
    "\n",
    "    for ai_model in ['DeepSeek-R1 14B']:\n",
    "        ai_details = gen_ai_config.model[ai_model]                          #   Get model info\n",
    "        df_dataset.insert(len(df_dataset.columns), ai_details['id'], '')    #   Create a new column or clear old data for the AI generated labels\n",
    "        for row in df_dataset.itertuples():\n",
    "            print(get_label(dataset_details, ai_details, row.text, row.event)[1])\n",
    "        #if 'event' in df_dataset.columns:\n",
    "        #    df_dataset[ai_details['id']] = df_dataset.apply(lambda row: get_label(dataset_details, ai_details, row.text, row.event)[1], axis=1)\n",
    "        #else:\n",
    "        #    df_dataset[ai_details['id']] = df_dataset.apply(lambda row: get_label(dataset_details, ai_details, row['text'])[1])\n",
    "#\n",
    "\n"
   ],
   "id": "72fe550bfa10591b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_dataset.to_csv(export_location, index_label=False)",
   "id": "f014cd150bdc7045",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
