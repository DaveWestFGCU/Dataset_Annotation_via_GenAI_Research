{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Config",
   "id": "acfe81e03e1e0855"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:40:26.302877Z",
     "start_time": "2025-03-10T23:40:26.299505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import_location = 'datasets/emoevent/raw/full_subset/ai_labeled/emoevent_ai_labeled_deterministic.csv'\n",
    "export_location = 'datasets/emoevent/raw/full_subset/ai_labeled/'\n",
    "export_name = 'emoevent_ai_labeled_deterministic.csv'\n",
    "\n",
    "datasets = ['EmoEvent']\n",
    "ai_models = ['Llama3.1 8B instruct-q8', 'DeepSeek-R1 14B', 'GPT 4o-mini'] # 'Llama3.1 8B instruct-q8', 'DeepSeek-R1 14B', 'GPT 4o-mini', 'o3-mini'\n",
    "overwrite_previous_labels = False\n",
    "deterministic = True\n",
    "\n",
    "random_seed = 418   #   I'm a teacup\n",
    "\n",
    "from config_files.dataset_config import dataset as dataset_config\n",
    "from config_files import gen_ai_config"
   ],
   "id": "32b45e63ad82cd11",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:40:26.325303Z",
     "start_time": "2025-03-10T23:40:26.322740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ollama\n",
    "from ollama import ResponseError\n",
    "from openai import OpenAI"
   ],
   "id": "f03fc15de4bb940c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Label Generation Functions",
   "id": "9764e2b6d75a906"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build Label Prompt",
   "id": "a918e211678ec10b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:40:26.334251Z",
     "start_time": "2025-03-10T23:40:26.330637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_label_prompt(dataset_id, text, ai_model, event = None):\n",
    "    from config_files import prompts\n",
    "\n",
    "    prompt = prompts.prompt[dataset_id]['labels'].replace('<text>', text)\n",
    "\n",
    "    # Get some \"thinking\" if not deepseek\n",
    "    if ai_model[:8] == 'deepseek' or deterministic:\n",
    "        response_instructions = prompts.prompt[dataset_id]['only label']\n",
    "    else:\n",
    "        response_instructions = prompts.prompt[dataset_id]['with considerations']\n",
    "\n",
    "    prompt = prompt.replace('<response instructions>', response_instructions)\n",
    "\n",
    "    # Add context for EmoEvent\n",
    "    if event:\n",
    "        prompt = prompt.replace('<context>', prompts.prompt[dataset_id]['context'][event])\n",
    "    else:\n",
    "        prompt = prompt.replace('<context>', \"\")\n",
    "\n",
    "    return prompt"
   ],
   "id": "32f515bfd9f6618a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate AI Label",
   "id": "1b29db45fe947948"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:40:26.348176Z",
     "start_time": "2025-03-10T23:40:26.343680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_synthetic_label(dataset_details, genAI_details, label_prompt, num_labelers = 1):\n",
    "    if genAI_details[\"platform\"] == \"Ollama\":\n",
    "        if deterministic:\n",
    "            response = ollama.chat(\n",
    "                model=genAI_details[\"id\"],\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": label_prompt\n",
    "                }],\n",
    "                options={\"top_k\":1, \"temperature\":0.0}   # Greedy\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            response = ollama.chat(\n",
    "                model=genAI_details[\"id\"],\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": label_prompt\n",
    "                }]\n",
    "            )\n",
    "\n",
    "        return response[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "    elif genAI_details[\"platform\"] == \"OpenAI\":\n",
    "        client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "        if deterministic:\n",
    "            response = client.chat.completions.create(\n",
    "                model=genAI_details[\"id\"],\n",
    "                messages = [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": label_prompt,\n",
    "                }],\n",
    "                n=1,\n",
    "                temperature=0.0 # Greedy\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "                model=genAI_details[\"id\"],\n",
    "                messages = [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": label_prompt,\n",
    "                }],\n",
    "                n=num_labelers\n",
    "            )\n",
    "\n",
    "        response_text = []\n",
    "        for choice in response.choices:\n",
    "            response_text.append(choice.message.content)\n",
    "\n",
    "        return response_text"
   ],
   "id": "6e1b881660a59d7c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Parse Label Response",
   "id": "4b9dcc9e7be8aaec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:40:26.360623Z",
     "start_time": "2025-03-10T23:40:26.357509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_label_response(response, dataset_details, cot_terminator = None):\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "\n",
    "    if cot_terminator:      #   Remove the reasoning layer text for Chain-of-Thought models\n",
    "        response.find(cot_terminator)\n",
    "        response = response[response.find(cot_terminator):]\n",
    "\n",
    "    for label in dataset_details[\"label_list\"]:\n",
    "        if f'**{label.lower()}**' in response.lower():\n",
    "            return label\n",
    "\n",
    "    # Label not found\n",
    "    CRED = '\\33[91m'\n",
    "    CEND = '\\33[0m'\n",
    "    print(f\"{CRED}NO LABEL FOUND:{CEND} {response}\")\n",
    "\n",
    "    return None"
   ],
   "id": "e69ede9675da0f53",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Label Record",
   "id": "4cdae0e93f5e0dd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:40:26.384826Z",
     "start_time": "2025-03-10T23:40:26.377794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_label(dataset_details, gen_ai_details, text, event=None):\n",
    "    label_prompt = build_label_prompt(dataset_details['id'], text, gen_ai_details['id'], event)\n",
    "\n",
    "    labels = []\n",
    "    responses = []\n",
    "    print(\"Labels: \", end=\"\")\n",
    "\n",
    "    if gen_ai_details[\"platform\"] == \"Ollama\":\n",
    "        if deterministic:\n",
    "            label = None\n",
    "            while label is None:\n",
    "                response = generate_synthetic_label(dataset_details, gen_ai_details, label_prompt)\n",
    "                label = parse_label_response(response, dataset_details, gen_ai_details['terminator'])\n",
    "\n",
    "                print(label)\n",
    "            return label, [label], [response]\n",
    "\n",
    "        for i in range(dataset_details['min_labelers']):\n",
    "            label = None\n",
    "            while label is None:   # Re-prompt if a label is not found (label probably wasn't generated in **double asterisks**)\n",
    "                response = generate_synthetic_label(dataset_details, gen_ai_details, label_prompt)\n",
    "                label = parse_label_response(response, dataset_details, gen_ai_details['terminator'])\n",
    "\n",
    "            responses.append(response)\n",
    "            labels.append(label)\n",
    "\n",
    "            if i == 0:\n",
    "                print(f\"{labels[i]}\", end=\"\")\n",
    "            else:\n",
    "                print(f\", {labels[i]}\", end=\"\")\n",
    "\n",
    "    elif gen_ai_details[\"platform\"] == \"OpenAI\":\n",
    "        if deterministic:\n",
    "            label = None\n",
    "            while label is None:\n",
    "                responses = generate_synthetic_label(dataset_details, gen_ai_details, label_prompt, dataset_details['min_labelers'])\n",
    "                label = parse_label_response(responses[0], dataset_details)\n",
    "\n",
    "                print(label)\n",
    "            return label, [label], responses\n",
    "\n",
    "        responses = generate_synthetic_label(dataset_details, gen_ai_details, label_prompt, dataset_details['min_labelers'])\n",
    "        for i, response in enumerate(responses):\n",
    "            label = parse_label_response(response, dataset_details)\n",
    "            if label is not None:\n",
    "                labels.append(label)\n",
    "\n",
    "            if i == 0:\n",
    "                print(f\"{labels[i]}\", end=\"\")\n",
    "            else:\n",
    "                print(f\", {labels[i]}\", end=\"\")\n",
    "\n",
    "    # Repeat if no consensus found\n",
    "    while len(labels) == len(set(labels)) and len(labels) < dataset_details['max_labelers']:\n",
    "        label = None\n",
    "\n",
    "        while label is None:   # Re-prompt if a label is not found (label probably wasn't generated in **double asterisks**)\n",
    "            response = generate_synthetic_label(dataset_details, gen_ai_details, label_prompt)\n",
    "            if isinstance(response, list):\n",
    "                response = response[0]\n",
    "            label = parse_label_response(response, dataset_details, gen_ai_details['terminator'])\n",
    "\n",
    "        responses.append(response)\n",
    "        labels.append(label)\n",
    "\n",
    "        print(f\", {label}\", end=\"\")\n",
    "\n",
    "\n",
    "    consensus_label = None\n",
    "    for potential_label in dataset_details[\"label_list\"]:\n",
    "        if labels.count(potential_label) >= dataset_details[\"num_consensus\"]:\n",
    "            consensus_label = potential_label\n",
    "    print(f\"\\n\\tConsensus: {consensus_label}\\n\")\n",
    "\n",
    "\n",
    "    return consensus_label, labels, responses"
   ],
   "id": "e13c00c10c4a16ea",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Main Loop",
   "id": "3a6fb57e4980dfa8"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-10T23:40:26.397239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset in datasets:\n",
    "    dataset_details = dataset_config[dataset]        #   Get dataset info\n",
    "\n",
    "    try:\n",
    "        df_dataset = pd.read_csv(import_location)    #  Load dataset\n",
    "    except FileNotFoundError:\n",
    "        df_dataset = pd.DataFrame()\n",
    "\n",
    "    for ai_model in ai_models:\n",
    "        ai_details = gen_ai_config.model[ai_model]   #   Get model info\n",
    "\n",
    "        try:\n",
    "            df_dataset.insert(len(df_dataset.columns), ai_details['id'], '')    #   Create a new column or clear old data for the AI generated labels\n",
    "\n",
    "        except ValueError:\n",
    "            if overwrite_previous_labels is True:\n",
    "                df_dataset[ai_details['id']] = ''\n",
    "\n",
    "        os.makedirs(os.path.join(export_location, 'ai_responses', ai_model), exist_ok=True)\n",
    "\n",
    "        for df_index, row in df_dataset.iterrows():\n",
    "            print(f'{ai_model} -> {df_index}')\n",
    "            successful = False\n",
    "            with open(os.path.join(export_location,'ai_responses', ai_model, f\"{dataset_details['id']}_{df_index}.txt\"), 'w', encoding=\"utf-8\") as file:\n",
    "                while not successful:\n",
    "                    try:\n",
    "                        if 'context' in df_dataset.columns:\n",
    "                            label, labels, responses = get_label(dataset_details, ai_details, row.text, row.context)\n",
    "                        else:\n",
    "                            label, labels, responses = get_label(dataset_details, ai_details, row.text)\n",
    "\n",
    "                    except ResponseError:  #   Recover from a CUDA illegal memory access error\n",
    "                        from time import sleep\n",
    "                        sleep(5)\n",
    "\n",
    "                    else:\n",
    "                        df_dataset.at[df_index, ai_details['id']] = label\n",
    "                        file.write(f\"Record: \\\"{df_dataset['text'].iloc[df_index]}\\\"\\n{ai_model}\\n{'-'*120}\\n\\n\")\n",
    "                        for response_index, line in enumerate(responses):\n",
    "                            file.write(f\"Response {response_index+1}:\\n{line}\\n{'-'*120}\\n\\n\")\n",
    "                        successful = True\n",
    "\n",
    "        display(df_dataset)\n",
    "        df_dataset.to_csv(os.path.join(export_location, export_name), index_label=False)\n"
   ],
   "id": "a63cc08dad8f0554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama3.1 8B instruct-q8 -> 0\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 1\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 2\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 3\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 4\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 5\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 6\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 7\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 8\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 9\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 10\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 11\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 12\n",
      "Labels: disgust\n",
      "Llama3.1 8B instruct-q8 -> 13\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 14\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 15\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 16\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 17\n",
      "Labels: surprise\n",
      "Llama3.1 8B instruct-q8 -> 18\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 19\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 20\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 21\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 22\n",
      "Labels: fear\n",
      "Llama3.1 8B instruct-q8 -> 23\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 24\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 25\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 26\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 27\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 28\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 29\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 30\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 31\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 32\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 33\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 34\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 35\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 36\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 37\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 38\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 39\n",
      "Labels: surprise\n",
      "Llama3.1 8B instruct-q8 -> 40\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 41\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 42\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 43\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 44\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 45\n",
      "Labels: disgust\n",
      "Llama3.1 8B instruct-q8 -> 46\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 47\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 48\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 49\n",
      "Labels: surprise\n",
      "Llama3.1 8B instruct-q8 -> 50\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 51\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 52\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 53\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 54\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 55\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 56\n",
      "Labels: disgust\n",
      "Llama3.1 8B instruct-q8 -> 57\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 58\n",
      "Labels: surprise\n",
      "Llama3.1 8B instruct-q8 -> 59\n",
      "Labels: surprise\n",
      "Llama3.1 8B instruct-q8 -> 60\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 61\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 62\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 63\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 64\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 65\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 66\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 67\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 68\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 69\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 70\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 71\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 72\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 73\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 74\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 75\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 76\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 77\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 78\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 79\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 80\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 81\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 82\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 83\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 84\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 85\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 86\n",
      "Labels: fear\n",
      "Llama3.1 8B instruct-q8 -> 87\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 88\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 89\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 90\n",
      "Labels: surprise\n",
      "Llama3.1 8B instruct-q8 -> 91\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 92\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 93\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 94\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 95\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 96\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 97\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 98\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 99\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 100\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 101\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 102\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 103\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 104\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 105\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 106\n",
      "Labels: disgust\n",
      "Llama3.1 8B instruct-q8 -> 107\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 108\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 109\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 110\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 111\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 112\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 113\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 114\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 115\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 116\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 117\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 118\n",
      "Labels: joy\n",
      "Llama3.1 8B instruct-q8 -> 119\n",
      "Labels: sadness\n",
      "Llama3.1 8B instruct-q8 -> 120\n",
      "Labels: anger\n",
      "Llama3.1 8B instruct-q8 -> 121\n",
      "Labels: "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "6fb445d0188259f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for dataset in datasets:\n",
    "    dataset_details = dataset_config[dataset]               #   Get dataset info\n",
    "    df_dataset = pd.read_csv(dataset_details['relpath'])    #  Load dataset\n",
    "\n",
    "    for ai_model in ['DeepSeek-R1 14B']:\n",
    "        ai_details = gen_ai_config.model[ai_model]                          #   Get model info\n",
    "        df_dataset.insert(len(df_dataset.columns), ai_details['id'], '')    #   Create a new column or clear old data for the AI generated labels\n",
    "        for row in df_dataset.itertuples():\n",
    "            print(get_label(dataset_details, ai_details, row.text, row.event)[1])\n",
    "        #if 'event' in df_dataset.columns:\n",
    "        #    df_dataset[ai_details['id']] = df_dataset.apply(lambda row: get_label(dataset_details, ai_details, row.text, row.event)[1], axis=1)\n",
    "        #else:\n",
    "        #    df_dataset[ai_details['id']] = df_dataset.apply(lambda row: get_label(dataset_details, ai_details, row['text'])[1])\n",
    "#\n",
    "\n"
   ],
   "id": "766c10974dfb6118"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_dataset.to_csv(os.path.join(export_location, export_name), index_label=False)\n",
    "\n",
    "df_dataset"
   ],
   "id": "995d86cd02e61396",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
